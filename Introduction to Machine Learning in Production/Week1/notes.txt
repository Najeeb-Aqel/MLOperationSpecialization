DeepLearning.AI community on Discourse: https://discourse.deeplearning.ai/invites/DPyjzgp8vJ

----Intro------------------------------------------------------------------------------------------------------------------------------


- ML is more than just running your experiment within a Jupyter notebook. 
- one misconsiption about ML is that after running the experiment within your notebook, you only need some software engineering skills 
for the Deployment but that is not true. 
- One of the biggest issue facing in production is that the distribution of the data that Model faces in real world can be different 
than what it was trained on, the world changes and thus your ML Model as well. Deployment as well. 


-Curriculum-
- Course1: Intro Course. Overview of the whole ML Life Cyle. 
- Course2: Data and how it evolves over time. 
- Course3: ML modeling pipeline in Production. 
- Course4: Deployment. 



----The Machine Learning Life Cycle-----------------------------------------------------------------------------------------------------

Welcome Section: 

- Edge Device: a device that lives in the factory manufacturing hardware. 
- Prediction servers can be on cloud or on the edge as well. 
- Concept Drift/ Data Drift: the problem of dealing with real world data that is differen than what you have trained on so far. 
- Success of training your model within a dev environment can take an extra work of up to 6 months to practical Deployment. (It's still a great Success but as ML Engineers we have to watch out for)
    - Some ML Team would not consider such problems as ML problems, Andrew NG doesn't agree here, he thinks that ML Team responsibility is to make things work. 
- MLCode represents 5-10% at max of the MLProject code required to get your model into Production. (POC to Production gap)


Steps of an ML Project

- Scoping: Defining project. 
- Data: Defining data, labeling and orgaizing. 
- Modeling: Select/Train model, error analysis. (Highly iterative)
- Deployment: When you deploy for the first time you are only half way there, you still required to maintain and monitro your system for any distribution changes.


Case study: speech recognition

- Modeling Stage:  
    - Data and not code: You can get and open source Architecture of the state of the art Architectures out there, and instead focus on optimizing Data and maybe hyperparamters. Achieving high accuracy. 
    - You don't need to collect more data, try to use error analysis to know exactly what kind of data you need to collect. 
- Deployment Stage: 
    - VAD: Voice Activity detection module. 


----Deployment--------------------------------------------------------------------------------------------------------------------------

Key challenges

- Concept Drift and data Drift: Data distribution changes in the real world, desired mapping between inputs to outputs shifted. 
    - how data changes? gradual change, sudden change.
        - Funny example: when the pandemic happened, a sudden shock occurred in the customer purchasing behavior (many people stated to shop online) and thus tripped up most of the fraud detection system. 
- software engineering issues:
    - RealTime vs Batch.
    - Cloub vs Edge/Browser.
    - Compute resources (CPU/GPU/memory).
    - Latency, throughput (QPS).
    - Logging.
    - Security & Privacy.


Deployment patterns

- New product/Capability: 
- Automate/assist with manual task:  
- Replace previous ML system: 

- patterns
    - shadow mode/ assess Learning algorithms to make decisions independently.
    - Canary Deployment: roll out to small fraction of traffic initially and then ram up.
    - Blue/Green Deployment: Have two Prediction services, Blue(Old/stabel) and Green (New), keep both active and just gradually switch to the new services.


Monitoring

- Dashboards:
    - Server Load
    - Non-null outputs fraction.
    - fraction of missing input values. 
- Metrics:
    - software metrics: memory, Compute, Latency
    - Input Metrics: Did distributiono of input data changed, Image Brightness. 
    - Output Metrics: how often returns null, how often doing the same search again and again. 
- Just as ML modeling is iterative, so is deployment.
- Setting Alarms. 
- Proper Monitoring could lead us to the wholly grail of Automating Training Process. 


Pipeline monitoring
- Record software/input/output metrics per module.
- How quickly do data change?