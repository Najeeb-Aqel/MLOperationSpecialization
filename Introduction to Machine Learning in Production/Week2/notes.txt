----Modeling overview----------------------------------------------------------------------------------------------------------------------

Mian problems:
    - Handling new datasets. 
    - good enough on test dataset but not goog enough in the real world. 



Key challenges:
    - AI System = Code + Data( Much more customized to your problem ) + hyperparamters(very limited). 
    - Error analysis. 


-----------Error analysis and performance auditing-----------------------------------------------------------------------------------------

Error analysis example
- Most of the time you are guaranteed that your ML solution won't work the first time.
- The heart of ML is to do Error analysis:
    - This step is more data/problem specific, (you can manually go through the data and Identify patters within your data).
    - Emerging tool to automate this process: https://landing.ai/platform/.
    - Examine/Tage examples --- propose tags. (Iterative process).
    

Skewed datastes:
- Definition: Positive/Negative data are far from being 50/50 ratio. 
- Using Precision/Recall/FScore is better than just plain accuracy as some classes might be very rare and thus have an average high accuracy. 


Performance auditing:
- Audit Performance (accuracy, fairness/bias, ): 
    - Brainstorm the ways the system might go wrong. 
    - Esablish metrics, to access performance against these issues on appropriate.
        - Automatic Evaluation: TFMA: automated metrics. 
    - Get business/product ownner buy-in. 
- Speech recognition example. 
    - Accuracy on different genders and ethnicities.
    - Accuracy on different devices. 
    - Prevalence of rude mis-transcriptions.


-----------Data Iteration ------------------------------------------------------------------------------------------------------------------

Data-centric AI development: 
    -

A useful picture of data augmentation:
    - space of possible inputs: Increasing performace of one space in the unstructured data-field will probably increase performace on other spaces as well, but rarely causing a degaradation in any spaces. 
    

Data augmentation:
    - Goal: Create realistic examples that the algorithm does poorly on, but humans do well on. 
    - Checklist: 
        - Does data sounds realistic. 
        - can humans perform well. 
        - is the algorithm doing poorly on it. 
    - GANs: can be overkill. 
    - Model Iteration: 


Can adding data hurt?
    - Rarely, when the augmentation reflect another target of data within your dataset. 
    - Even that training dataset disctribution is different thatn testing and validation datases, that shouldn't hurt performace.  









