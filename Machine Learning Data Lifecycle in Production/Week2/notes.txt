-----------------------------------Feature Engineering-------------------------------------------------------

- Introduction to Preprocessing: 
    - the ar of feature Engineering is to improve model's ability to learn and reduce if possibel the compute resouces it needs. 

- Preprocessing Operations: 
    - Data Cleansing. 
    - Feature Tuning.
    - Represenation and Transformation.
    - Feature Extraction. 
    - Feature Construction. 

- Feature Engineering Techniques: 
    - Numberical Range: Scaling, noramlization, standardizing. 
        - Scaling: helps neural network converge faster, for each feature the model learns the right weight, does away with NaN errorsduring training.
        - noramlization: X - Xmin / (Xmax - Xmin), not good with Gaussian/normal data. 
        - standardizing: X - mean / Standard deviation. 
    - Grouping: Bag of words, Bucketizing.

- Feature Crosses: 
    - Basically combining multiple features in a new feature.
    

-----------------------------------Feature Transformation at scale-------------------------------------------------------

- Preprocessing Data at Scale:
    - Consisting Transofrms on both serving and training. 
    - One of the challenges is when Serving and training code paths are different Taining in Python and serving in C++ for example:
        - this can Introduce skews and thus reduce model performance.
    - Prefetching transformations:accelareate data Preprocessing and thus make use fo your accelerator hardware. 