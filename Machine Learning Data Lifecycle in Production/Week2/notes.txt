-----------------------------------Feature Engineering-------------------------------------------------------

- Introduction to Preprocessing: 
    - the ar of feature Engineering is to improve model's ability to learn and reduce if possibel the compute resouces it needs. 

- Preprocessing Operations: 
    - Data Cleansing. 
    - Feature Tuning.
    - Represenation and Transformation.
    - Feature Extraction. 
    - Feature Construction. 

- Feature Engineering Techniques: 
    - Numberical Range: Scaling, noramlization, standardizing. 
        - Scaling: helps neural network converge faster, for each feature the model learns the right weight, does away with NaN errorsduring training.
        - noramlization: X - Xmin / (Xmax - Xmin), not good with Gaussian/normal data. 
        - standardizing: X - mean / Standard deviation. 
    - Grouping: Bag of words, Bucketizing.

- Feature Crosses: 
    - Basically combining multiple features in a new feature.
    

-----------------------------------Feature Transformation at scale-------------------------------------------------------

- Preprocessing Data at Scale:
    - Consisting Transofrms on both serving and training. 
    - One of the challenges is when Serving and training code paths are different Taining in Python and serving in C++ for example:
        - this can Introduce skews and thus reduce model performance.
    - Prefetching transformations:accelareate data Preprocessing and thus make use fo your accelerator hardware. 


-----------------------------------Feature Selection --------------------------------------------------------------------

- Feature Spaces: 
    - N dimentionsal space defined by your N features.
    - Not Including the Target label. 

- Feature Selection: 
    - Identify the features that best represent the realtionship between x-Y.
    - Remove features that don't influence the outcome. 
    - Reduce the size of the feature space. 
    
    Why:
        - Reduces storage and I/O requirements. 
        - Minimize training and inference costs.


    Filtered Methods: 
        - Correlation: 
            - correlated features are usually redundant. 
                - Pearson Correlation: 
        - Univariate Feature Selection: 
    
